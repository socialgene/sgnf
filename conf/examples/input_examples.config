/*
    Use as follows:
        // The curl command downloads MIBiG BGC0000001 from Genbank
        curl -s "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=JF752342.1&rettype=gbwithparts&retmode=text" | gzip > "/tmp/JF752342.1.gb.gz"
        outdir='/home/chase/Documents/socialgene_data/input_examples'

        nextflow run . \
            -profile input_examples,conda \
            --single_outdir $outdir \
            -resume

----------------------------------------------------------------------------------------
*/

params {
        // Use the downloaded BGC0000001 as input
        local_genbank = '/tmp/JF752342.1.gb.gz'

        // Use https://github.com/ncbi/datasets to download the genome assembly of the producing organism
        ncbi_datasets_command       = 'genome accession "GCF_000204155.1"'

        // Use https://github.com/kblin/ncbi-genome-download to donwload all Micromonospora maris assemblies
        // usually you will probably run ncbi_datasets_command or ncbi_genome_download_command, as in this case it will download GCF_000204155 twice
        ncbi_genome_download_command = '--species-taxids 1003110 bacteria'

    /*
    ////////////////////////
    set which modules to run
    ////////////////////////
    */
        hmmlist         = ["antismash"]
        mmseqs2         = true
        blastp          = false // only set to true for small datasets
        ncbi_taxonomy   = true
        build_database  = true
    /*
    ////////////////////////
    adjust per your computer
    ////////////////////////
    */
        fasta_splits                = 23
        max_cpus                    = 23
        max_memory                  = '62.GB'
        max_time                    = 6000.h

}

process {
    withName:HMMER_HMMSEARCH {
       cpus   = { check_max( 1    * task.attempt, 'cpus'    ) }
       memory = { check_max( 2    * task.attempt, 'memory'  ) }
       time   = { check_max( 60.h * task.attempt, 'time'   ) }
    }
}
