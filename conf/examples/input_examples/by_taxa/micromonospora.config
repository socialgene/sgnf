/*
Use as follows:
   outdir='/tmp/socialgene_data/m2'
        outdir_download_cache='/tmp/socialgene_data/cache'
    nextflow run . \
    -profile micromonospora,docker \
    --outdir $outdir \
    --outdir_download_cache $outdir_download_cache \
    -resume
----------------------------------------------------------------------------------------
*/

params {
    config_profile_name          = 'Annotate all RefSeq Micromonospora'
    config_profile_description   = 'Minimal test dataset to check pipeline function'
    ncbi_datasets_command        ='genome taxon "micromonospora" --assembly-source refseq --exclude-atypical'

    /*
    ///////////////////////////////////
    Set which additional modules to run
    ///////////////////////////////////
    */
        mibig           = true
        hmmlist         = 'antismash,amrfinder,pfam,resfams,tigrfam'
        mmseqs_steps    = '90,70,50,30'
        ncbi_taxonomy   = true
        build_database  = true
        antismash       = true

    /*
    ////////////////////////
    Adjust per your computer
    ////////////////////////
    */
        // If running the pipeline on a single computer, fasta_splits should be set at the same
        // number as max_cpus. For very large input data you might
        // want to set fasta_splits to a higher number to allow checkpointing. Howevever, setting
        // fasta_splits too high will result in diminishing returns due to overhead and possibly
        // too-few proteins per file (would probably keep <1000 for any size of dataset)
        max_cpus                    = 96
        max_memory                  = '800.GB'
        max_time                    = 500.h
        slurm_queue_size            = 48

}

process {

withName:HMMER_HMMSEARCH {
        cpus   = { check_max (2     * task.attempt, 'cpus'   ) }
        memory = { check_max (2.GB * task.attempt, 'memory' ) }
        time   = { check_max (24.h  * task.attempt, 'time'   ) }
    }
    withLabel:process_single {
        cpus   = { check_max( 1                    , 'cpus'    ) }
        memory = { check_max( 5.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 10.h  * task.attempt  , 'time'    ) }
    }
    withLabel:process_low {
        cpus   = { check_max( 1     * task.attempt, 'cpus'    ) }
        memory = { check_max( 2.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 40.h   * task.attempt, 'time'    ) }
    }
    withLabel:process_medium {
        cpus   = { check_max( 5     * task.attempt, 'cpus'    ) }
        memory = { check_max( 20.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 80.h   * task.attempt, 'time'    ) }
    }
    withLabel:process_high {
        cpus   = { check_max( 24    * task.attempt, 'cpus'    ) }
        memory = { check_max( 100.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 16.h  * task.attempt, 'time'    ) }
    }
    withLabel:process_long {
        time   = { check_max( 24.h  * task.attempt, 'time'    ) }
    }
    withLabel:process_high_memory {
        memory = { check_max( 400.GB * task.attempt, 'memory' ) }
    }   
    
}
