/*
========================================================================================
    Nextflow config file for analyzing genomes in the paper: "Comparative and pangenomic analysis of the genus Streptomyces"
    https://doi.org/10.1038/s41598-022-21731-1
========================================================================================
    The first command creates files to send to HTCONDOR:

        outdir='/tmp/socialgene_data/jgi_steptomyces_pangenome'
        outdir_download_cache='/tmp/socialgene_data/cache'

        nextflow run . \
            -profile jgi_streptomyces_pangenome,docker \
            --outdir $outdir \
            --outdir_download_cache $outdir_download_cache \
            --fasta_splits 1000 \
            --htcondor \
            -resume

    # The second parses the HTCONDOR results and then runs all other computation (e.g. BLASTp, MMseqs2)
        nextflow run . \
            -profile jgi_streptomyces_pangenome,docker \
            --outdir $outdir \
            --domtblout_path '/tmp/socialgene_data/jgi_steptomyces_pangenome/htcondor_cache/chtc_results/chtc_results/*.domtblout.gz' \
            -resume

----------------------------------------------------------------------------------------
*/

params {
    local_genbank = '/tmp/socialgene_data/jgi_paper/ncbi-genomes-2022-11-09/*.gbff.gz'

    /*
    ////////////////////////
    set which modules to run
    ////////////////////////
    */
        mibig           = false
        mmseqs_steps    = '90'
        blastp          = true
        ncbi_taxonomy   = true
        build_database  = true
        antismash       = true

    /*

    ////////////////////////
    Adjust per your computer
    ////////////////////////
    */
        // If running the pipeline on a single computer, fasta_splits should be set at the same
        // number as max_cpus. For very large input data you might
        // want to set fasta_splits to a higher number to allow checkpointing. Howevever, setting
        // fasta_splits too high will result in diminishing returns due to overhead and possibly
        // too-few proteins per file (would probably keep <1000 for any size of dataset)
        fasta_splits                = 24
        max_cpus                    = 24
        max_memory                  = '60.GB'
        max_time                    = 6000.h

}

process {

    withName:DIAMOND_BLASTP {
        cpus = 24
        ext.args = "-k0 --max-hsps 1 --query-cover 70 --subject-cover 70 --id 80  --fast"
    }

    withName:'MMSEQS2_CLUSTER'{
        ext.args = '--min-seq-id 0.8 -c 0.7 --cov-mode 0'
    }
}
