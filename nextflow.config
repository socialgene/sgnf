/*
========================================================================================
    socialgene/sgnf Nextflow config file
========================================================================================
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/


manifest {
    name            = 'socialgene/sgnf'
    author          = """Chase M. Clark"""
    homePage        = 'https://github.com/socialgene/sgnf'
    description     = """Scalable genome mining with SocialGene knowledge graphs"""
    mainScript      = 'main.nf'
    defaultBranch   = 'main'
    nextflowVersion = '!>=22.10.1'
    version         = '0.2.4' // x-release-please-version
    doi             = ''
}



// Global default params, used in configs
params {
    input = "not-used-but-needed-in-lint"
    fasta = "not-used-but-needed-in-lint"

    // Boilerplate options
    email                      = null
    email_on_fail              = null
    plaintext_email            = false
    monochrome_logs            = false
    hook_url                   = null
    help                       = false
    version                    = false
    validate_params            = true
    show_hidden_params         = false
    schema_ignore_params       = 'genomes'

    // Config options
    custom_config_version      = 'master'
    custom_config_base         = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
    config_profile_description = null
    config_profile_contact     = null
    config_profile_url         = null
    config_profile_name        = null

    // Tuning resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '62.GB'
    max_cpus                   = 12
    max_time                   = '16.h'
    slurm_queue_size           = 12

    // ADDITIONAL CONFIGS
    mibig                           = null
    local_genbank                   = null
    local_fasta                     = null
    ncbi_datasets_command           = null
    ncbi_genome_download_command    = null
    ncbi_datasets_file              = null
    hmm_splits                      = 1
    fasta_splits                    = 0
    genbank_input_buffer            = 50 // Decides how many parallel processes  will be used for genbank parsing; number of spawned parse processes = (# of input genomes) / (genbank_input_buffer)
    build_database                  = true
    sort_fasta                      = false  // used for tests to ensure nr-fasta are the same regardless of execution order

    // Results Directories
    outdir                      = "socialgene_results"
    outdir_per_run              = "${params.outdir}/socialgene_per_run"
    outdir_blast_cache          = "${params.outdir_per_run}/blastp_cache"
    outdir_download_cache       = "${params.outdir}/socialgene_long_cache"
    outdir_neo4j                = "${params.outdir}/socialgene_neo4j"
    outdir_genomes              = "${params.outdir}/genome_download_cache"
    tracedir                    = "${params.outdir_per_run}/pipeline_info"
    paired_omics_json_path      = null

    // sg_modules
    blastp                      = false
    mmseqs_steps                = null   // e.g. '90 70 50' for 90% 70% 50%
    antismash                   = false
    chembl                      = false
    paired_omics                = false
    ncbi_taxonomy               = false
    hmmlist                     = null // antismash,amrfinder,bigslice,classiphage,pfam,prism,resfams,tigrfam,virus_orthologous_groups
    custom_hmm_file             = null
    goterms                     = false

    // HMM database versions (databases without download versioning are unlisted)
    amrfinder_version           = '2021-03-01.1'
    antismash_hmms_git_sha      = 'e2d777c6cd035e6bf20f7eec924a350b00b84c7b'
    bigslice_version           = 'v1.0.0/bigslice-models.2020-04-27'
    pfam_version                = '35.0'
    tigrfam_version             = '15.0'
    vog_version                 = 'vog211'
    chembl_version              = '31'

    // These effect which HMMS hits are significant and reported
    HMMSEARCH_Z         =   100000000
    HMMSEARCH_IEVALUE   =   0.1
    HMMSEARCH_E         =   100.0
    HMMSEARCH_DOME      =   10.0
    HMMSEARCH_INCE      =   0.001
    HMMSEARCH_INCDOME   =   0.001
    hmmsearch_model_threshold = "--cut_ga"

    // You can probably ignore these parameters
    HMMSEARCH_F1 = 0.02
    HMMSEARCH_F2 = 0.001
    HMMSEARCH_F3 = 1e-05
    HMMSEARCH_SEED = 42

    // Unless you're using the multi-step high throuput computing pipeline, you don't need to worry about these
    htcondor_request_cpus   = 1
    htcondor_request_memory = '1GB'
    htcondor_request_disk   = '5GB'
    htcondor_max_idle       = 100
    htcondor_squid_username = 'cmclark8'
    htcondor_WantGlideIn    = true
    htcondor_WantFlocking   = true
    htcondor_prep_directory      = "${params.outdir}/htcondor_cache"
    htcondor                = null

    domtblout_path          = null

    // MultiQC options
    multiqc_config             = null
    multiqc_title              = null
    multiqc_logo               = null
    max_multiqc_email_size     = '25.MB'
    multiqc_methods_description = null

    // Docker image versions (versions are synchronized with Nextflow pipeline version)
    sgnf_antismash_dockerimage  = null
    sgnf_hmmer_plus_dockerimage = null
    sgnf_hmmer_dockerimage      = null
    sgnf_minimal_dockerimage    = null
    sgnf_sgpy_dockerimage       = null
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'


// Load nf-core custom profiles from different Institutions
try {
    includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
    System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

includeConfig 'conf/modules.config'

profiles {
    debug {
        dumpHashes             = true
        process.beforeScript   = 'echo $HOSTNAME'
        cleanup = false
    }
    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    docker {
        docker.enabled         = true
        docker.registry        = null
        docker.userEmulation   = true
        conda.enabled          = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    arm {
        docker.runOptions = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        conda.enabled          = false
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    podman {
        podman.enabled         = true
        podman.registry        = 'quay.io'
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    shifter {
        shifter.enabled        = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    charliecloud {
        charliecloud.enabled   = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        apptainer.enabled      = false
    }
    apptainer {
        apptainer.enabled      = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    gitpod {
        executor.name          = 'local'
        executor.cpus          = 16
        executor.memory        = 60.GB
    }


    slurm {
        process.executor = "slurm"
        process.queue    = "queue"
        executor {
                queueSize = params.slurm_queue_size
        }
    }


    // compute_platform
    htcondor                    { includeConfig 'conf/examples/compute_platform/htcondor.config'                      }

    // input_examples
    input_examples              { includeConfig 'conf/examples/input_examples/input_examples.config'                  }
    refseq                      { includeConfig 'conf/examples/input_examples/bgc_genome_databases/refseq.config'     }

    // input_examples/by_taxa
    actinomycetia               { includeConfig 'conf/examples/input_examples/by_taxa/actinomycetia.config'           }
    micromonospora              { includeConfig 'conf/examples/input_examples/by_taxa/micromonospora.config'          }
    ncbi_datasets               { includeConfig 'conf/examples/input_examples/by_taxa/ncbi_datasets.config'           }
    streptomyces_coelicolor     { includeConfig 'conf/examples/input_examples/by_taxa/streptomyces_coelicolor.config' }
    streptomyces                { includeConfig 'conf/examples/input_examples/by_taxa/streptomyces.config'            }

    // input_examples/protein_databases
    cog                         { includeConfig 'conf/examples/input_examples/protein_databases/cog.config'           }
    swissprot                   { includeConfig 'conf/examples/input_examples/protein_databases/swissprot.config'     }
    uniref100                   { includeConfig 'conf/examples/input_examples/protein_databases/uniref100.config'     }

    // other
    jgi_streptomyces_pangenome  { includeConfig 'conf/examples/other/jgi_streptomyces_pangenome.config'               }
    mandelalides                { includeConfig 'conf/examples/other/mandelalides.config'                             }
    mibig_genomes               { includeConfig 'conf/examples/other/mibig_genomes.config'                            }
    mibig                       { includeConfig 'conf/examples/other/mibig.config'                                    }

    ultraquickstart             { includeConfig 'conf/examples/ultraquickstart.config'                                }
    test                        { includeConfig 'conf/tests/test.config'                                              }




}
// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.html"
}

includeConfig 'conf/modules2.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
